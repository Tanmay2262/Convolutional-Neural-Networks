{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importing the Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "tf.__version__"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing the Training set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_datagen = ImageDataGenerator(\r\n",
    "        rescale=1./255,\r\n",
    "        shear_range=0.2,\r\n",
    "        zoom_range=0.2,\r\n",
    "        horizontal_flip=True)\r\n",
    "\r\n",
    "training_set = train_datagen.flow_from_directory(\r\n",
    "        r'C:\\Users\\ghode\\Python\\Cats&Dogs\\10.1 Section 40 - Convolutional Neural Networks (CNN)\\Section 40 - Convolutional Neural Networks (CNN)\\dataset\\training_set',\r\n",
    "        target_size=(64, 64),\r\n",
    "        batch_size=32,\r\n",
    "        class_mode='binary')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 7176 images belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing the Test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\r\n",
    "\r\n",
    "test_set = test_datagen.flow_from_directory(\r\n",
    "        r'C:\\Users\\ghode\\Python\\Cats&Dogs\\10.1 Section 40 - Convolutional Neural Networks (CNN)\\Section 40 - Convolutional Neural Networks (CNN)\\dataset\\test_set',\r\n",
    "        target_size=(64, 64),\r\n",
    "        batch_size=32,\r\n",
    "        class_mode='binary')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building the CNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialising the CNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1 - Convolution "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", input_shape=[64, 64,3]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2 - Pooling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adding a second Convolutional Layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"))\r\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step - 3 Flattening"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step - 4 Full Connection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step - 5 Adding the output layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training the CNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compiling the CNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "cnn.compile(optimizer='adam', loss='binary_crossentropy' ,metrics= ['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the CNN on the Training set and evaluating it on the Test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs=25)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/25\n",
      "225/225 [==============================] - 29s 127ms/step - loss: 0.6761 - accuracy: 0.5900 - val_loss: 0.6608 - val_accuracy: 0.6315\n",
      "Epoch 2/25\n",
      "225/225 [==============================] - 25s 113ms/step - loss: 0.6212 - accuracy: 0.6614 - val_loss: 0.6312 - val_accuracy: 0.6530\n",
      "Epoch 3/25\n",
      "225/225 [==============================] - 26s 116ms/step - loss: 0.5834 - accuracy: 0.6993 - val_loss: 0.5951 - val_accuracy: 0.6765\n",
      "Epoch 4/25\n",
      "225/225 [==============================] - 26s 116ms/step - loss: 0.5404 - accuracy: 0.7320 - val_loss: 0.5332 - val_accuracy: 0.7250\n",
      "Epoch 5/25\n",
      "225/225 [==============================] - 26s 116ms/step - loss: 0.5204 - accuracy: 0.7433 - val_loss: 0.5233 - val_accuracy: 0.7265\n",
      "Epoch 6/25\n",
      "225/225 [==============================] - 26s 116ms/step - loss: 0.4977 - accuracy: 0.7565 - val_loss: 0.5092 - val_accuracy: 0.7650\n",
      "Epoch 7/25\n",
      "225/225 [==============================] - 26s 117ms/step - loss: 0.4904 - accuracy: 0.7575 - val_loss: 0.4710 - val_accuracy: 0.7700\n",
      "Epoch 8/25\n",
      "225/225 [==============================] - 26s 116ms/step - loss: 0.4720 - accuracy: 0.7727 - val_loss: 0.4740 - val_accuracy: 0.7815\n",
      "Epoch 9/25\n",
      "225/225 [==============================] - 26s 117ms/step - loss: 0.4512 - accuracy: 0.7868 - val_loss: 0.4788 - val_accuracy: 0.7760\n",
      "Epoch 10/25\n",
      "225/225 [==============================] - 26s 118ms/step - loss: 0.4441 - accuracy: 0.7862 - val_loss: 0.4652 - val_accuracy: 0.7865\n",
      "Epoch 11/25\n",
      "225/225 [==============================] - 26s 117ms/step - loss: 0.4342 - accuracy: 0.7977 - val_loss: 0.4587 - val_accuracy: 0.7790\n",
      "Epoch 12/25\n",
      "225/225 [==============================] - 25s 113ms/step - loss: 0.4120 - accuracy: 0.8110 - val_loss: 0.4538 - val_accuracy: 0.7935\n",
      "Epoch 13/25\n",
      "225/225 [==============================] - 26s 113ms/step - loss: 0.3970 - accuracy: 0.8141 - val_loss: 0.4848 - val_accuracy: 0.7970\n",
      "Epoch 14/25\n",
      "225/225 [==============================] - 28s 122ms/step - loss: 0.3844 - accuracy: 0.8255 - val_loss: 0.4664 - val_accuracy: 0.8035\n",
      "Epoch 15/25\n",
      "225/225 [==============================] - 25s 113ms/step - loss: 0.3760 - accuracy: 0.8318 - val_loss: 0.4426 - val_accuracy: 0.8025\n",
      "Epoch 16/25\n",
      "225/225 [==============================] - 25s 113ms/step - loss: 0.3582 - accuracy: 0.8390 - val_loss: 0.4705 - val_accuracy: 0.7790\n",
      "Epoch 17/25\n",
      "225/225 [==============================] - 25s 113ms/step - loss: 0.3511 - accuracy: 0.8471 - val_loss: 0.4850 - val_accuracy: 0.7875\n",
      "Epoch 18/25\n",
      "225/225 [==============================] - 25s 112ms/step - loss: 0.3320 - accuracy: 0.8527 - val_loss: 0.4632 - val_accuracy: 0.8050\n",
      "Epoch 19/25\n",
      "225/225 [==============================] - 25s 113ms/step - loss: 0.3266 - accuracy: 0.8523 - val_loss: 0.4794 - val_accuracy: 0.7940\n",
      "Epoch 20/25\n",
      "225/225 [==============================] - 25s 113ms/step - loss: 0.3178 - accuracy: 0.8648 - val_loss: 0.4701 - val_accuracy: 0.8110\n",
      "Epoch 21/25\n",
      "225/225 [==============================] - 25s 113ms/step - loss: 0.3095 - accuracy: 0.8623 - val_loss: 0.4493 - val_accuracy: 0.8015\n",
      "Epoch 22/25\n",
      "225/225 [==============================] - 26s 114ms/step - loss: 0.2899 - accuracy: 0.8754 - val_loss: 0.4980 - val_accuracy: 0.8005\n",
      "Epoch 23/25\n",
      "225/225 [==============================] - 26s 114ms/step - loss: 0.2791 - accuracy: 0.8767 - val_loss: 0.4846 - val_accuracy: 0.7990\n",
      "Epoch 24/25\n",
      "225/225 [==============================] - 27s 120ms/step - loss: 0.2658 - accuracy: 0.8860 - val_loss: 0.5111 - val_accuracy: 0.7970\n",
      "Epoch 25/25\n",
      "225/225 [==============================] - 26s 117ms/step - loss: 0.2706 - accuracy: 0.8891 - val_loss: 0.4879 - val_accuracy: 0.7980\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2545983efd0>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Making a single prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "from keras.preprocessing import image\r\n",
    "test_image = tf.keras.preprocessing.image.load_img(\r\n",
    "    r'C:\\Users\\ghode\\Python\\Cats&Dogs\\10.1 Section 40 - Convolutional Neural Networks (CNN)\\Section 40 - Convolutional Neural Networks (CNN)\\dataset\\single_prediction\\cat_or_dog_2.jpg', target_size=(64,64))\r\n",
    "tf.keras.preprocessing.image.img_to_array(test_image)\r\n",
    "test_image = np.expand_dims(test_image, axis=0)\r\n",
    "result = cnn.predict(test_image)\r\n",
    "training_set.class_indices\r\n",
    "if result[0][0] == 1:\r\n",
    "    prediction = 'dog'\r\n",
    "else:\r\n",
    "    prediction = 'cat'\r\n",
    "\r\n",
    "print(prediction)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cat\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "74ed0e5f1755517b3d4873d578eb35f0ff67078cb4e7f5f7aa1026f95cefa531"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}